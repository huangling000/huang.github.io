

在hdfs中，如果上传一个大文件，文件会被按64MB每个block来分割到不同的datanode上。在hdfs中添加小于一个文件块的大小的文件，实际占用linux文件系统的大小仍然是文件大小，而非一个hdfs系统中一个块（默认64M）的大小。那么hdfs中设置块的大小还有必要吗，有什么作用？

**hdfs设置block的目的**

1 为什么通常选择64M或者128，256M（最优选择）？

不能太小的原因：

1 减少硬盘寻道时间：hdfs设计是为了支持大容量数据，如果数据块大小设置过小，需要读取的数据块更多，增大了总的硬盘寻道时间。合适的大小有助于减少硬盘寻道时间，提高系统吞吐量。

2 减少namenode内存消耗：namenode上会记录datanode上的数据块的元信息，如果数据块大小设置过小，需要维护的数据块信息增加，增加namenode内存消耗。

不能太大的原因：

1 监管时间问题：主节点监管其他的节点的时间间隔的预设不好估计。太大时时间间隔短了导致datanode节点任务还没有做完被判定为死亡，时间间隔长了可能在这段时间内节点早已死亡，主节点浪费等待时间。

2 问题分解问题：对于相同的算法，数据量越大，时间复杂度越大。

**block与split**

1 block是物理上的数据分割，而split是逻辑上的分割。

2 如果没有特别指定，split size 就等于 HDFS 的 block size 。用户可以在M/R 程序中自定义split size。

3 一个split 可以包含多个blocks，也可以把一个block应用多个split操作。

4 一个split不会包含两个File的Block,不会跨越File边界

5 有多少个split，就有多少个mapper。